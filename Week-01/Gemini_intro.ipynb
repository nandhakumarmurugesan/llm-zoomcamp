{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f38ad2-30e1-4958-8a0d-4b05c341819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37fd1000-21d8-49e5-93f9-5151c806009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e55de82-e383-484c-958a-695e2ae280b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd687598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39bfb951-4a29-43ae-a574-0a7bbfb08977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16983504-8ffb-4a0f-a6ca-fa5dbf5014de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mos\u001b[49m.environ[\u001b[33m\"\u001b[39m\u001b[33mGOOGLE_API_KEY\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mYOUR KEYYYYY\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR KEYYYYY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e42e86f3-d0a5-42ac-9f69-b6e457b2166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50a5c016-fa66-493f-a9bf-daa8b67479cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.genai.client.Client at 0x719ce9187bc0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b76e39a-0658-4ce8-8b78-06163b20a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af322007-fe31-43e3-a5b7-00737bb9876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e1bd443-937f-458e-b14a-2633e2f61809",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make predictions or decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\", \n",
    "            contents=\"Explain how AI works in a few words?\"\n",
    "        )\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5dd91ad9-88d9-47a6-97f8-929dadcf1e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Machines mimicking human intelligence to perform tasks autonomously.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "# Create the client and chat instance\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "#chat = model.create_message()\n",
    "chat = client.chats.create(model = model_name)\n",
    "# Send user message\n",
    "user_message = \"explain about AI in 10 words\"\n",
    "response = chat.send_message(user_message)\n",
    "\n",
    "# Print model response\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f9a2f9f-0e13-4497-9aed-c3d0a62a3460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay! That's nice to know. Do you want to tell me anything else about your dogs? Like their names, breeds, or ages? Or perhaps you have a question about dog care?\n",
      "\n",
      "Since you have two dogs, and each dog has four paws, there are 2 * 4 = 8 paws from the dogs.\n",
      "\n",
      "Unless you are also walking around on all fours, there are 8 paws in your house.\n",
      "\n",
      "role - user: I have 2 dogs in my house.\n",
      "role - model: Okay! That's nice to know. Do you want to tell me anything else about your dogs? Like their names, breeds, or ages? Or perhaps you have a question about dog care?\n",
      "\n",
      "role - user: How many paws are in my house?\n",
      "role - model: Since you have two dogs, and each dog has four paws, there are 2 * 4 = 8 paws from the dogs.\n",
      "\n",
      "Unless you are also walking around on all fours, there are 8 paws in your house.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
    "\n",
    "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
    "print(response.text)\n",
    "\n",
    "response = chat.send_message(\"How many paws are in my house?\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87d0c488-8864-4f7b-bae5-ce7927cd5ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay! Two dogs can be a lot of fun. Is there anything you'd like to tell me about them, or anything I can help you with regarding your dogs? For example:\n",
      "\n",
      "*   **What are their names and breeds?**\n",
      "*   **How old are they?**\n",
      "*   **Are you having any challenges with them (training, behavior, etc.)?**\n",
      "*   **Do you want to share a funny story about them?**\n",
      "\n",
      "I'm here to listen!\n",
      "If you have 2 dogs, and each dog has 4 paws, then there are 8 paws in your house. (2 dogs * 4 paws/dog = 8 paws)\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
    "\n",
    "response = chat.send_message_stream(\"I have 2 dogs in my house.\")\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")\n",
    "\n",
    "response = chat.send_message_stream(\"How many paws are in my house?\")\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")\n",
    "\n",
    "for message in chat.get_history():\n",
    "    print(f'role - {message.role}', end=\": \")\n",
    "    print(message.parts[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9085280b-58a1-45ee-b879-5dc58eb23303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role - user: I have 2 dogs in my house.\n",
      "role - model: Okay! That's nice to know. Do you want to tell me anything else about your dogs? Like their names, breeds, or ages? Or perhaps you have a question about dog care?\n",
      "\n",
      "role - user: How many paws are in my house?\n",
      "role - model: Since you have two dogs, and each dog has four paws, there are 2 * 4 = 8 paws from the dogs.\n",
      "\n",
      "Unless you are also walking around on all fours, there are 8 paws in your house.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in chat.get_history():\n",
    "    print(f'role - {message.role}',end=\": \")\n",
    "    print(message.parts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29da8438-06d2-4c0e-ad44-29bca041b422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: user, Content: explain about AI in 10 words\n",
      "Role: model, Content: AI: Machines mimicking human intelligence to automate tasks and solve problems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in chat.get_history():\n",
    "    # Accessing text content from parts [6]\n",
    "    text_content = \"\"\n",
    "    if hasattr(message.parts, 'text'):\n",
    "        text_content = message.parts.text\n",
    "    elif isinstance(message.parts, list) and message.parts:\n",
    "        # Handle cases where parts might be a list (e.g., multimodal content)\n",
    "        text_content = ' '.join([p.text for p in message.parts if hasattr(p, 'text')])\n",
    "    print(f'Role: {message.role}, Content: {text_content}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3245f6d3-7a57-4e83-ad0e-1796be958ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chat History ---\n",
      "Role: user, Content: explain about AI in 10 words\n",
      "Role: model, Content: AI: Machines mimicking human intelligence to automate tasks and solve problems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Chat History ---\")\n",
    "# Print full chat history\n",
    "for message in chat.get_history():\n",
    "    role = message.role\n",
    "    content = \" \".join(part.text for part in message.parts if hasattr(part, 'text'))\n",
    "    print(f'Role: {role}, Content: {content}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acb323c3-0935-4860-99af-07d66b31c489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a large language model, I don't experience feelings or emotions in the same way humans do. I don't have a body to feel tired or hungry.\n",
      "\n",
      "However, I can tell you that I am functioning as expected and ready to assist you with any questions or tasks you may have!  So, in that sense, I am doing well. How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Approach 2: Using the google-genai SDK's generate_content() (for Simple, Single-Shot Prompts)\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "# --- Content Generation ---\n",
    "# Send a single content prompt. The 'contents' parameter accepts a list of parts\n",
    "response = client.models.generate_content(\n",
    "    model = model_name,\n",
    "    contents = [\"how are you\"]\n",
    ")\n",
    "# Print the model's response text\n",
    "print(response.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbaf4bbd-667a-4e2a-b7a0-1198286fa55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# client = OpenAI()\n",
    "# response = client.chat.completions.create(\n",
    "#     model = 'gpt-4o',\n",
    "#     messages=[{\"role\": \"user\", \"content\" : \"how are you\"}]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b093447b-f7ba-446b-b93a-91fe43bd88bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m response = client.models.generate_content_stream(\n\u001b[32m      2\u001b[39m             model=\u001b[33m\"\u001b[39m\u001b[33mgemini-2.0-flash\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m      3\u001b[39m             contents=\u001b[33m\"\u001b[39m\u001b[33mExplain how AI works in a 20?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m         )\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# for chunk in response:\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#             print(chunk.text)\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#             print(\"_\" * 80)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m) \n",
      "\u001b[31mAttributeError\u001b[39m: 'generator' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# response = client.models.generate_content_stream(\n",
    "#             model=\"gemini-2.0-flash\", \n",
    "#             contents=\"Explain how AI works in a 20?\"\n",
    "#         )\n",
    "# # for chunk in response:\n",
    "# #             print(chunk.text)\n",
    "# #             print(\"_\" * 80)\n",
    "# print(response.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06abce0-dd92-4062-ba62-696321e3417c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda7a2b-9c2f-4f08-bc1c-ed30983ae067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
